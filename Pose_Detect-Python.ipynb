{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54c467cc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9ea74ef",
   "metadata": {},
   "source": [
    "# 1. Make data phase\n",
    "\n",
    "Make data by yourself using camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c5d532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you thing you have library :v\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dcc82b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Else run this if you thing you don't have\n",
    "%pip install opencv-python\n",
    "%pip install mediapipe\n",
    "%pip install pandas\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6d4131",
   "metadata": {},
   "source": [
    "### Read information from camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9b8a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# If got error, try to replace index 0 by 1, 2,..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8cafc6",
   "metadata": {},
   "source": [
    "### Using mediapipe lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2e3b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpPose = mp.solutions.pose\n",
    "pose = mpPose.Pose()\n",
    "mpDraw = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f361ca7",
   "metadata": {},
   "source": [
    "### Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb6349",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_list = []           # List of frame's landmarks\n",
    "labels = \"HEADSWING\"   # Name of the movement which you take data \n",
    "no_of_frames = 600     # Frames you take data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdf76cb",
   "metadata": {},
   "source": [
    "## Function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb0977c",
   "metadata": {},
   "source": [
    "### Function to extract frame's landmarks and storage in lm_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4b6e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_landmark_timestep(results):\n",
    "    print(results.pose_landmarks.landmark)\n",
    "    c_lm = []\n",
    "    for id, lm in enumerate(results.pose_landmarks.landmark):\n",
    "        c_lm.append(lm.x)\n",
    "        c_lm.append(lm.y)\n",
    "        c_lm.append(lm.z)\n",
    "        c_lm.append(lm.visibility)\n",
    "    return c_lm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcf9e36",
   "metadata": {},
   "source": [
    "### Function draw landmark on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6864f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmark_on_image(mpDraw, results, img):\n",
    "\n",
    "    # Draw lines\n",
    "    mpDraw.draw_landmarks(img, results.pose_landmarks, mpPose.POSE_CONNECTIONS)\n",
    "\n",
    "    # Draw nodes\n",
    "    for id, lm in enumerate(results.pose_landmarks.landmark):\n",
    "        h, w, c = img.shape\n",
    "        print(id, lm)\n",
    "        cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "        cv2.circle(img, (cx, cy), 10, (0, 0, 255), cv2.FILLED)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4213d660",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while len(lm_list) <= no_of_frames:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "\n",
    "        # Pose recognition\n",
    "        frameRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(frameRGB)\n",
    "        if results.pose_landmarks:\n",
    "\n",
    "            # Append skeleton's paramaters to lm_list\n",
    "            lm = make_landmark_timestep(results)\n",
    "            lm_list.append(lm)\n",
    "\n",
    "            # Draw skeleton on image\n",
    "            frame = draw_landmark_on_image(mpDraw, results, frame)\n",
    "        cv2.imshow('image', frame)\n",
    "        if cv2.waitKey(1) == ord(\"q\"):   # If press Q button, end the window\n",
    "            break\n",
    "\n",
    "# Write data to csv file     \n",
    "df = pd.DataFrame(lm_list)\n",
    "df.to_csv(labels + \".txt\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76581bd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831de7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d799e5e",
   "metadata": {},
   "source": [
    "# 2. Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae6b305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you think you have library :v\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037402fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Else run this if you think you don't have\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install tensorflow\n",
    "%pip install keras\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aca84fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []  \n",
    "Y = []\n",
    "data_name = [\"HEADSWING.txt\", \"HANDSWING.txt\", \"BODYSWING.txt\"]   # Training CSV files\n",
    "no_of_timestep = 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45af08d2",
   "metadata": {},
   "source": [
    "### Turn each 10 data frames (timestep) into 1 data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7d837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(3):\n",
    "    data = pd.read_csv(data_name[idx])\n",
    "    dataset = data.iloc[:, 1:].values\n",
    "    n_sample = len(dataset)\n",
    "    for i in range(no_of_timestep, n_sample):\n",
    "        X.append(dataset[i - no_of_timestep:i, :])  # Láº¥y get 10 serial timestep\n",
    "        Y.append(idx)\n",
    "        # 0 is Headswing\n",
    "        # 1 is Handswing\n",
    "        # 2 is Bodyswing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98141d6a",
   "metadata": {},
   "source": [
    "### Convert X, y to numpy arrray and divide to train, validate, test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14385593",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.array(X), np.array(Y)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb64713a",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2a0008",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605cfa54",
   "metadata": {},
   "source": [
    "### View model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40ffb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446c136d",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dd1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", metrics=['accuracy'], loss=\"sparse_categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a867aa1",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd6eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=16, batch_size=32, validation_data=(X_test, y_test))\n",
    "model.save('model_multi.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf71a907",
   "metadata": {},
   "source": [
    "# 3. Inference Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96def043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you think you have library :v\n",
    "import cv2\n",
    "import keras\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb8b31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Else run this if you think you don't have\n",
    "%pip install opencv-python\n",
    "%pip install tensorflow\n",
    "%pip install keras\n",
    "%pip install numpy\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65b761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read frame from Camera\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7787e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize Mediapipe\n",
    "mpPose = mp.solutions.pose\n",
    "pose = mpPose.Pose()\n",
    "mpDraw = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cc1e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_list = []\n",
    "no_of_frames = 600\n",
    "\n",
    "i = 0\n",
    "warmup_frame = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3ed957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = keras.models.load_model(\"model_multi.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74508ce2",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbad5570",
   "metadata": {},
   "source": [
    "### Draw landmarks on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c592926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmark_on_image(mpDraw, results, img):\n",
    "    # Draw lines\n",
    "    mpDraw.draw_landmarks(img, results.pose_landmarks, mpPose.POSE_CONNECTIONS)\n",
    "\n",
    "    # Draw nodes\n",
    "    for id, lm in enumerate(results.pose_landmarks.landmark):\n",
    "        h, w, c = img.shape\n",
    "        # print(id, lm)\n",
    "        cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "        cv2.circle(img, (cx, cy), 10, (0, 0, 255), cv2.FILLED)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15d0212",
   "metadata": {},
   "source": [
    "### Make timestep's landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a2a33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_landmark_timestep(results):\n",
    "    # print(results.pose_landmarks.landmark)\n",
    "    c_lm = []\n",
    "    for id, lm in enumerate(results.pose_landmarks.landmark):\n",
    "        c_lm.append(lm.x)\n",
    "        c_lm.append(lm.y)\n",
    "        c_lm.append(lm.z)\n",
    "        c_lm.append(lm.visibility)\n",
    "    return c_lm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1af3d3a",
   "metadata": {},
   "source": [
    "### Draw class on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dba2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_class_on_image(label, img):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfText = (10, 30)\n",
    "    fontScale = 1\n",
    "    fontColor = (0, 255, 0)\n",
    "    thickness = 2\n",
    "    lineType = 2\n",
    "    cv2.putText(img, label,\n",
    "                bottomLeftCornerOfText,\n",
    "                font,\n",
    "                fontScale,\n",
    "                fontColor,\n",
    "                thickness,\n",
    "                lineType)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d950b3c",
   "metadata": {},
   "source": [
    "### From the result, detect the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ec7760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(model, lm_list):\n",
    "    global label\n",
    "    lm_list = np.array(lm_list)\n",
    "    lm_list = np.expand_dims(lm_list, axis=0)\n",
    "    print(lm_list.shape)\n",
    "    results = model.predict(lm_list)\n",
    "    print(results.shape)\n",
    "    lb_idx = np.argmax(results, axis=1)\n",
    "    if lb_idx == 0:\n",
    "        label = \"Headswing\"\n",
    "    elif lb_idx == 1:\n",
    "        label = \"Handswing\"\n",
    "    elif lb_idx == 2:\n",
    "        label = \"Bodyswing\"\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c313b9",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a55ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Warmup....\"\n",
    "while len(lm_list) <= no_of_frames:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "\n",
    "        # Pose detection\n",
    "        frameRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(frameRGB)\n",
    "        i = i + 1\n",
    "        if i > warmup_frame:\n",
    "            print(\"Start Detect...\")\n",
    "            if results.pose_landmarks:\n",
    "\n",
    "                # Get landmark points\n",
    "                lm = make_landmark_timestep(results)\n",
    "                lm_list.append(lm)\n",
    "                if len(lm_list) == 10:\n",
    "                    # Feed to model to detect\n",
    "                    t1 = threading.Thread(target=detect, args=(model, lm_list,))\n",
    "                    t1.start()\n",
    "                    lm_list = []\n",
    "                # Draw skeleton to image(frame)\n",
    "                frame = draw_landmark_on_image(mpDraw, results, frame)\n",
    "        frame = draw_class_on_image(label, frame)\n",
    "        cv2.imshow('image', frame)\n",
    "        if cv2.waitKey(1) == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
